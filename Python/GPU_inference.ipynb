{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8c4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on binary test set: 98.3%\n",
      "Accuracy on original test set: 98.95%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load Lenet model in GPU\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def binary_transform(image):\n",
    "    return (image > 0).float()\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.pool1(self.conv1(x)))\n",
    "        x = torch.relu(self.pool2(self.conv2(x)))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(-1, 120 * 1 * 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loaded_model = torch.load('lenet.pth')\n",
    "loaded_model.to(device)  \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "    binary_transform\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_transform_original = transforms.Compose([\n",
    "    transforms.Pad(2),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_dataset_original = datasets.MNIST('./data', train=False, download=True, transform=test_transform_original)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "test_loader_original = torch.utils.data.DataLoader(test_dataset_original, batch_size=10000, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)  \n",
    "        targets = targets.to(device)\n",
    "        outputs = loaded_model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "\n",
    "print(f'Accuracy on binary test set: {100 * correct / total}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader_original:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = loaded_model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f'Accuracy on original test set: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995e4034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynvml\n",
      "  Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
      "     -------------------------------------- 53.1/53.1 kB 119.2 kB/s eta 0:00:00\n",
      "Installing collected packages: pynvml\n",
      "Successfully installed pynvml-11.5.3\n"
     ]
    }
   ],
   "source": [
    "! pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the time and power consumption corresponding to inferring an image on the GPU\n",
    "\n",
    "\"\"\"\n",
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "total_time = 0;\n",
    "count=10000\n",
    "for i in range (count):\n",
    "\n",
    "    data_original, target_original = test_dataset_original[i]\n",
    "    data_tensor = data_original.to(device)\n",
    "\n",
    "    start_time = time.perf_counter_ns()\n",
    "    outputs =loaded_model(data_tensor)\n",
    "    end_time = time.perf_counter_ns()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    total_time += execution_time\n",
    "\n",
    "print(device)\n",
    "print(count)\n",
    "print(f\"One inference timeï¼š{total_time/count} ns\")\n",
    "powerusage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000\n",
    "print(f\"GPU Power Usage: {powerusage} w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
